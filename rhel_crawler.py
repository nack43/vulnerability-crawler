import requests
import datetime
import csv
import re
from bs4 import BeautifulSoup


def main():

    content = fetch()
    rhel_data = scrape(content)

    rhel_data = date_format(rhel_data)
    
    # pass 7 days to get the last week
    target_week = fetch_target(rhel_data, 7)
    
    cve_list = []
    if len(target_week) == 0:
        print('No New Vulnerabilitis In The Last Week :)')
    else:
        for line in target_week:            
            #print('\t'.join([str(elem) for elem in line]))
            cve_info_list = fetch_cve_info(line[2])
            line.append(cve_info_list)
            cve_list.append(line)
        print(cve_list)
        

def fetch():

    # get html object(text) with split(\n)
    content = requests.get('https://rhn.redhat.com/errata/rhel-server-6-errata.html').text.split('\n')
    return content


def scrape(content):

    # grep errataTableData
    data_def = ''
    for line in content:
        if 'errataTableData' in line:
            data_def = line
            break

    # generate a char array from the HTML
    char_arr = []
    prev = ''
    write_to_arr = False
    
    # ignore 
    for char in data_def:
        if write_to_arr:
            char_arr.append(char)
        if char == '[' and prev == '[':
            write_to_arr = True
        if char == ']' and prev == ']':
            write_to_arr = False
        prev = char

    # re-join blocks at beginning of the char_arr
    data_str = '[[' + ''.join(char_arr)

    # turn string into 2d array
    data = [row.replace('[', '').replace(']', '').split(',')[1:] for row in data_str.split('],[')]
    
    # trim href out out of <a> tag
    data = [row[:-2] + ['https://rhn.redhat.com' + row[-2].split('href="')[1].split('">')[0]] + row[-2:] for row in data if 'href' in row[-2]]

    # snip inner HTML out of <a> tag
    data = [row[:-2] + [row[-2].split('>')[1].split('<')[0]] + [row[-1]] for row in data]
    return data


# change date type string to datetime to compare to target week
# eliminate list element which is no date 
def date_format(formatted_list):

    formatted_list_date = []
    for i in range(0, len(formatted_list)):
        if re.search(r'201.-..-*', formatted_list[i][-1]) != None:
            formatted_list[i][-1] = datetime.datetime.strptime(formatted_list[i][-1], "'%Y-%m-%d'").date() 
            formatted_list_date.append(formatted_list[i])
    return formatted_list_date


def fetch_target(rhel_data, lookback_days):
    
    today = datetime.date.today()
    last_week = today - datetime.timedelta(days=today.weekday() + 1 + lookback_days)
    target_week = []

    for i in range(0, len(rhel_data)): 
        if rhel_data[i][-1] > last_week:
            target_week.append(rhel_data[i])
    return target_week


# return cve info dict {'href', 'num'}
def fetch_cve_info(url):
    cve_info_list = []
    r = requests.get(url)
    soup = BeautifulSoup(r.content, 'html.parser')
    cves = soup.find(rowspan='2').find_all('a')
    for cve in cves:
         cve_info_list.append({'href': cve.get('href'), 'num': cve.string})
    
    return cve_info_list


# __main__: module name is named by __main__ when the python script execute directly
# if this module is called by other module by import statement, the main() does not execute
if __name__ == '__main__':
    main()

